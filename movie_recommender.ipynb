{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29bc5fdd",
   "metadata": {},
   "source": [
    "# Content-Based Movie Recommendation System\n",
    "\n",
    "## Project Overview\n",
    "This notebook builds a content-based recommendation system using the TMDB 5000 Movie Dataset.\n",
    "The system recommends movies based on similarity in content features like overview, genres, keywords, and cast.\n",
    "\n",
    "## Dataset\n",
    "- TMDB 5000 Movie Dataset from Kaggle\n",
    "- Two CSV files: tmdb_5000_movies.csv and tmdb_5000_credits.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1706a7e8",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a89605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9c0cfe",
   "metadata": {},
   "source": [
    "## 2. Load the Dataset\n",
    "\n",
    "**Note:** Download the TMDB 5000 Movie Dataset from Kaggle:\n",
    "- https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata\n",
    "- Place `tmdb_5000_movies.csv` and `tmdb_5000_credits.csv` in the same folder as this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2702441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "movies = pd.read_csv('tmdb_5000_movies.csv')\n",
    "credits = pd.read_csv('tmdb_5000_credits.csv')\n",
    "\n",
    "print(f\"Movies shape: {movies.shape}\")\n",
    "print(f\"Credits shape: {credits.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aa2116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"Movies Dataset:\")\n",
    "display(movies.head())\n",
    "\n",
    "print(\"\\nCredits Dataset:\")\n",
    "display(credits.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34ae127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns\n",
    "print(\"Movies columns:\", movies.columns.tolist())\n",
    "print(\"\\nCredits columns:\", credits.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d23389",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58adf6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets on title\n",
    "movies = movies.merge(credits, on='title')\n",
    "print(f\"Merged dataset shape: {movies.shape}\")\n",
    "movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd5e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns\n",
    "movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]\n",
    "print(f\"Selected columns: {movies.columns.tolist()}\")\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272b462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(movies.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71570ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in critical columns\n",
    "movies.dropna(inplace=True)\n",
    "print(f\"Dataset shape after dropping nulls: {movies.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3acde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(f\"Duplicate rows: {movies.duplicated().sum()}\")\n",
    "movies = movies.drop_duplicates()\n",
    "print(f\"Shape after removing duplicates: {movies.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67694f63",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering - Extract Information from JSON Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893ed02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract names from genres/keywords (list of dictionaries)\n",
    "def convert(obj):\n",
    "    try:\n",
    "        L = []\n",
    "        for i in ast.literal_eval(obj):\n",
    "            L.append(i['name'])\n",
    "        return L\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# Test the function\n",
    "print(\"Sample genres before:\", movies['genres'].iloc[0])\n",
    "print(\"Sample genres after:\", convert(movies['genres'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb89f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to genres and keywords\n",
    "movies['genres'] = movies['genres'].apply(convert)\n",
    "movies['keywords'] = movies['keywords'].apply(convert)\n",
    "\n",
    "print(\"Genres converted successfully\")\n",
    "movies[['title', 'genres', 'keywords']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e9a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract top 3 cast members\n",
    "def convert_cast(obj):\n",
    "    try:\n",
    "        L = []\n",
    "        counter = 0\n",
    "        for i in ast.literal_eval(obj):\n",
    "            if counter < 3:\n",
    "                L.append(i['name'])\n",
    "                counter += 1\n",
    "            else:\n",
    "                break\n",
    "        return L\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "movies['cast'] = movies['cast'].apply(convert_cast)\n",
    "print(\"Cast converted successfully\")\n",
    "movies[['title', 'cast']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f1e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract director from crew\n",
    "def fetch_director(obj):\n",
    "    try:\n",
    "        L = []\n",
    "        for i in ast.literal_eval(obj):\n",
    "            if i['job'] == 'Director':\n",
    "                L.append(i['name'])\n",
    "        return L\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "movies['crew'] = movies['crew'].apply(fetch_director)\n",
    "movies.rename(columns={'crew': 'director'}, inplace=True)\n",
    "\n",
    "print(\"Director extracted successfully\")\n",
    "movies[['title', 'director']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a914490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert overview to list of words\n",
    "movies['overview'] = movies['overview'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "\n",
    "print(\"Overview converted to list\")\n",
    "movies[['title', 'overview']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4df8e24",
   "metadata": {},
   "source": [
    "## 5. Data Cleaning - Remove Spaces from Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd132c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove spaces from multi-word names to treat them as single tokens\n",
    "def remove_space(L):\n",
    "    if isinstance(L, list):\n",
    "        return [i.replace(\" \", \"\") for i in L]\n",
    "    return L\n",
    "\n",
    "movies['cast'] = movies['cast'].apply(remove_space)\n",
    "movies['director'] = movies['director'].apply(remove_space)\n",
    "movies['genres'] = movies['genres'].apply(remove_space)\n",
    "movies['keywords'] = movies['keywords'].apply(remove_space)\n",
    "\n",
    "print(\"Spaces removed from names\")\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bb2d70",
   "metadata": {},
   "source": [
    "## 6. Create Tags Column - Combine All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c275fe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all features into a single 'tags' column\n",
    "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['director']\n",
    "\n",
    "print(\"Tags column created\")\n",
    "movies[['title', 'tags']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46936fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with only necessary columns\n",
    "new_df = movies[['movie_id', 'title', 'tags']].copy()\n",
    "\n",
    "print(f\"New dataframe shape: {new_df.shape}\")\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f21f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tags list to string\n",
    "new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x) if isinstance(x, list) else \"\")\n",
    "\n",
    "print(\"Tags converted to string\")\n",
    "print(\"\\nSample tags:\")\n",
    "print(new_df['tags'].iloc[0][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81156d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to lowercase\n",
    "new_df['tags'] = new_df['tags'].apply(lambda x: x.lower())\n",
    "\n",
    "print(\"Tags converted to lowercase\")\n",
    "print(\"\\nSample tags after lowercase:\")\n",
    "print(new_df['tags'].iloc[0][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec92af8",
   "metadata": {},
   "source": [
    "## 7. Vectorization - Convert Text to Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111b5cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using CountVectorizer with stemming\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features=5000, stop_words='english')\n",
    "vectors = cv.fit_transform(new_df['tags']).toarray()\n",
    "\n",
    "print(f\"Vectors shape: {vectors.shape}\")\n",
    "print(f\"Number of movies: {vectors.shape[0]}\")\n",
    "print(f\"Number of features: {vectors.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61b83f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature names\n",
    "print(\"Sample feature names:\")\n",
    "print(cv.get_feature_names_out()[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f377f1e5",
   "metadata": {},
   "source": [
    "## 8. Apply Stemming for Better Results (Optional but Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1135ccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install nltk if not already installed\n",
    "# !pip install nltk\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    print(\"NLTK data downloaded\")\n",
    "except:\n",
    "    print(\"NLTK data already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40743f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply stemming\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stem(text):\n",
    "    y = []\n",
    "    for i in text.split():\n",
    "        y.append(ps.stem(i))\n",
    "    return \" \".join(y)\n",
    "\n",
    "new_df['tags'] = new_df['tags'].apply(stem)\n",
    "\n",
    "print(\"Stemming applied\")\n",
    "print(\"\\nSample tags after stemming:\")\n",
    "print(new_df['tags'].iloc[0][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481a49cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-vectorize after stemming\n",
    "cv = CountVectorizer(max_features=5000, stop_words='english')\n",
    "vectors = cv.fit_transform(new_df['tags']).toarray()\n",
    "\n",
    "print(f\"Vectors shape after stemming: {vectors.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf734b3d",
   "metadata": {},
   "source": [
    "## 9. Calculate Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71599010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between all movie vectors\n",
    "similarity = cosine_similarity(vectors)\n",
    "\n",
    "print(f\"Similarity matrix shape: {similarity.shape}\")\n",
    "print(f\"\\nSample similarity scores for first movie:\")\n",
    "print(similarity[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f36d6ba",
   "metadata": {},
   "source": [
    "## 10. Build Recommendation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88863de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(movie):\n",
    "    \"\"\"\n",
    "    Recommend top 5 similar movies based on content similarity\n",
    "    \n",
    "    Parameters:\n",
    "    movie (str): Title of the movie\n",
    "    \n",
    "    Returns:\n",
    "    list: List of 5 recommended movie titles\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the index of the movie\n",
    "        movie_index = new_df[new_df['title'] == movie].index[0]\n",
    "        \n",
    "        # Get similarity scores for this movie with all other movies\n",
    "        distances = similarity[movie_index]\n",
    "        \n",
    "        # Sort movies based on similarity scores and get top 6 (including the movie itself)\n",
    "        movies_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:6]\n",
    "        \n",
    "        # Get movie titles\n",
    "        recommended_movies = []\n",
    "        for i in movies_list:\n",
    "            recommended_movies.append(new_df.iloc[i[0]].title)\n",
    "        \n",
    "        return recommended_movies\n",
    "    \n",
    "    except IndexError:\n",
    "        return f\"Movie '{movie}' not found in the database. Please check the title and try again.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09d9b02",
   "metadata": {},
   "source": [
    "## 11. Test the Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ec8a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with some popular movies\n",
    "print(\"Recommendations for 'Avatar':\")\n",
    "print(recommend('Avatar'))\n",
    "\n",
    "print(\"\\nRecommendations for 'The Dark Knight':\")\n",
    "print(recommend('The Dark Knight'))\n",
    "\n",
    "print(\"\\nRecommendations for 'Inception':\")\n",
    "print(recommend('Inception'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963f0162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available movie titles\n",
    "print(f\"Total movies in database: {len(new_df)}\")\n",
    "print(\"\\nSample movie titles:\")\n",
    "print(new_df['title'].head(20).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949347e3",
   "metadata": {},
   "source": [
    "## 12. Save Models and Data for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1e68f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the movie dataframe\n",
    "pickle.dump(new_df, open('movies.pkl', 'wb'))\n",
    "print(\"Movies dataframe saved as 'movies.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ef93ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the similarity matrix\n",
    "pickle.dump(similarity, open('similarity.pkl', 'wb'))\n",
    "print(\"Similarity matrix saved as 'similarity.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba32be86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the vectorizer (optional)\n",
    "pickle.dump(cv, open('vectorizer.pkl', 'wb'))\n",
    "print(\"Vectorizer saved as 'vectorizer.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06350fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify saved files\n",
    "import os\n",
    "\n",
    "files = ['movies.pkl', 'similarity.pkl', 'vectorizer.pkl']\n",
    "for file in files:\n",
    "    if os.path.exists(file):\n",
    "        size = os.path.getsize(file) / (1024 * 1024)  # Size in MB\n",
    "        print(f\"✓ {file} - {size:.2f} MB\")\n",
    "    else:\n",
    "        print(f\"✗ {file} - Not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c2cb44",
   "metadata": {},
   "source": [
    "## 13. Enhanced Recommendation Function with Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0408ffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_with_details(movie):\n",
    "    \"\"\"\n",
    "    Recommend movies with similarity scores\n",
    "    \"\"\"\n",
    "    try:\n",
    "        movie_index = new_df[new_df['title'] == movie].index[0]\n",
    "        distances = similarity[movie_index]\n",
    "        movies_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:6]\n",
    "        \n",
    "        print(f\"Top 5 recommendations for '{movie}':\\n\")\n",
    "        for idx, (i, score) in enumerate(movies_list, 1):\n",
    "            print(f\"{idx}. {new_df.iloc[i].title} (Similarity: {score:.4f})\")\n",
    "        \n",
    "    except IndexError:\n",
    "        print(f\"Movie '{movie}' not found in the database.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Test\n",
    "recommend_with_details('Avatar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f5ac8e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Built:\n",
    "1. ✅ Loaded and merged TMDB movie and credits datasets\n",
    "2. ✅ Extracted features: overview, genres, keywords, cast, and director\n",
    "3. ✅ Created a combined 'tags' column with all features\n",
    "4. ✅ Applied text preprocessing: lowercase, stemming, and space removal\n",
    "5. ✅ Vectorized text using CountVectorizer (5000 features)\n",
    "6. ✅ Calculated cosine similarity matrix\n",
    "7. ✅ Built recommend() function returning top 5 similar movies\n",
    "8. ✅ Saved models using pickle for deployment\n",
    "\n",
    "### Files Created:\n",
    "- `movies.pkl` - Movie dataframe with titles and tags\n",
    "- `similarity.pkl` - Cosine similarity matrix\n",
    "- `vectorizer.pkl` - Fitted CountVectorizer\n",
    "\n",
    "### Next Steps:\n",
    "- Build Streamlit app for interactive UI\n",
    "- Add movie posters using TMDB API\n",
    "- Deploy to cloud platform"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
